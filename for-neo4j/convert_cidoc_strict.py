"""
ä¸¥æ ¼éµå¾ª cidoc-kg-def3.csv çš„ CIDOC-CRM æ˜ å°„è§„åˆ™ï¼Œ
å°†é¡¹ç›®å¯¼å‡ºçš„ CSV æ•°æ®è½¬æ¢ä¸º Neo4j å¯å¯¼å…¥çš„èŠ‚ç‚¹ / å…³ç³» CSVã€‚

è¾“å‡ºç›®å½•ï¼šneo4j_cidoc_import/
"""

import os
import re
import hashlib
from typing import Dict, Any, Tuple

import pandas as pd

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
FOR_NEO4J_DIR = os.path.join(BASE_DIR, "for-neo4j")

DEFINITIONS_FILE = os.path.join(FOR_NEO4J_DIR, "cidoc-kg-def3.csv")

DATA_FILES = {
    "é™¶å™¨": os.path.join(FOR_NEO4J_DIR, "pottery_artifacts_export_20251203.csv"),
    "ç‰å™¨": os.path.join(FOR_NEO4J_DIR, "jade_artifacts_export_20251203.csv"),
    "é—å€": os.path.join(FOR_NEO4J_DIR, "sites_export_20251203.csv"),
    "æ—¶æœŸ": os.path.join(FOR_NEO4J_DIR, "periods_export_20251203.csv"),
}

STRUCTURES_FILE = os.path.join(FOR_NEO4J_DIR, "site_structures_export_20251203.csv")

OUTPUT_DIR = os.path.join(BASE_DIR, "neo4j_cidoc_import")


# ========= å·¥å…·å‡½æ•° =========

def clean_label(text: Any) -> str:
    """æ¸…ç† CIDOC ç±»åï¼Œå¦‚ 'E22 Man-Made Object' -> 'E22_ManMade_Object'"""
    if not isinstance(text, str):
        return "Unknown"
    s = text.strip()
    # å»æ‰æ‹¬å·ä¸­çš„ä¸­æ–‡è¯´æ˜
    s = re.sub(r"\(.*?\)", "", s)
    s = s.replace("-", "")
    parts = s.split()
    if not parts:
        return "Unknown"
    code = parts[0]
    rest = "".join(parts[1:])
    return f"{code}_{rest}" if rest else code


def clean_rel(text: Any) -> str:
    """æ¸…ç†å…³ç³»åï¼Œå¦‚ 'P45 consists of (ç”±...ç»„æˆ)' -> 'P45_consists_of'"""
    if not isinstance(text, str):
        return ""
    s = text.strip()
    # å»æ‰ LaTeX / $ / \text{ }
    s = s.replace("\\text", "")
    s = s.replace("{", "").replace("}", "").replace("$", "")
    # åªå–ä¸­æ–‡æ‹¬å·å‰é¢çš„è‹±æ–‡éƒ¨åˆ†
    s = s.split("ï¼ˆ")[0].split("(")[0].strip()
    m = re.match(r"(P\d+)\s*(.*)", s)
    if not m:
        return s.replace(" ", "_")
    pid, rest = m.groups()
    rest = rest.strip()
    if not rest:
        return pid
    rest = rest.replace(" ", "_")
    return f"{pid}_{rest}"


def get_uid(prefix: str, value: Any) -> str:
    """æ ¹æ®å‰ç¼€å’ŒåŸå§‹å€¼ç”Ÿæˆç¨³å®šçš„å­—ç¬¦ä¸² ID"""
    h = hashlib.md5(str(value).encode("utf-8")).hexdigest()[:10]
    return f"{prefix}_{h}"


# ========= æ˜ å°„è§„åˆ™è§£æ =========

def load_mapping_rules() -> Dict[Tuple[str, str], Dict[str, Any]]:
    """
    åŠ è½½ cidoc-kg-def3.csvï¼Œç”Ÿæˆï¼š
    (æ–‡ç‰©ç±»å‹, å­—æ®µä¸­æ–‡å) -> { domain, rel1, inter_class, rel2, range_class }
    """
    if not os.path.exists(DEFINITIONS_FILE):
        raise FileNotFoundError(f"ç¼ºå°‘å®šä¹‰æ–‡ä»¶: {DEFINITIONS_FILE}")

    df_def = pd.read_csv(DEFINITIONS_FILE)
    rules: Dict[Tuple[str, str], Dict[str, Any]] = {}

    for _, row in df_def.iterrows():
        art_type = str(row.get("æ–‡ç‰©ç±»å‹", "")).strip()
        field_cn = str(row.get("æŠ½å–å±æ€§ï¼šæ–‡åŒ–ç‰¹å¾å•å…ƒ", "")).strip()
        if not art_type or not field_cn or field_cn == "nan":
            continue

        domain_raw = row.get("æ ¸å¿ƒå®ä½“ï¼ˆDomainï¼‰", "")
        prop_raw = row.get("å…³ç³» (Property)", "")
        inter_raw = row.get("ä¸­é—´ç±» (Class)", "")
        subprop_raw = row.get("å­å±æ€§ (Sub-Property)", "")
        range_raw = row.get("ç›®æ ‡ç±» (Range Class)", "")

        domain = clean_label(domain_raw)
        rel1 = clean_rel(prop_raw)
        inter_class = None
        rel2 = None
        if isinstance(inter_raw, str) and inter_raw.strip() and inter_raw.strip() != "N/A":
            inter_class = clean_label(inter_raw)
            rel2 = clean_rel(subprop_raw) if isinstance(subprop_raw, str) else ""
        range_class = clean_label(range_raw)

        rules[(art_type, field_cn)] = {
            "domain": domain,
            "rel1": rel1,
            "inter_class": inter_class,
            "rel2": rel2,
            "range_class": range_class,
        }

    print(f"âœ… å·²è§£ææ˜ å°„è§„åˆ™ {len(rules)} æ¡")
    return rules


# ========= èŠ‚ç‚¹ / å…³ç³» å­˜å‚¨ç»“æ„ =========

class GraphBuilder:
    def __init__(self) -> None:
        # label -> id -> props
        self.nodes: Dict[str, Dict[str, Dict[str, Any]]] = {}
        # list of relations
        self.rels: list[Dict[str, str]] = []

    def add_node(self, label: str, uid: str, props: Dict[str, Any] | None = None) -> None:
        if label not in self.nodes:
            self.nodes[label] = {}
        if uid not in self.nodes[label]:
            self.nodes[label][uid] = {"id": uid}
        if props:
            # ä¸è¦†ç›–å·²æœ‰é”®
            for k, v in props.items():
                if v is None or v == "" or v != v:  # NaN
                    continue
                if k not in self.nodes[label][uid]:
                    self.nodes[label][uid][k] = v

    def add_rel(self, start_id: str, end_id: str, rel_type: str) -> None:
        if not start_id or not end_id or not rel_type:
            return
        self.rels.append(
            {
                ":START_ID": start_id,
                ":END_ID": end_id,
                ":TYPE": rel_type,
            }
        )

    # ===== å¯¼å‡º =====
    def export(self, output_dir: str) -> None:
        os.makedirs(output_dir, exist_ok=True)

        # èŠ‚ç‚¹
        for label, table in self.nodes.items():
            if not table:
                continue
            # æ±‡æ€»æ‰€æœ‰å­—æ®µ
            keys = set()
            for props in table.values():
                keys.update(props.keys())
            keys.discard("id")
            cols = ["id:ID", ":LABEL"] + sorted(keys)
            rows = []
            for uid, props in table.items():
                row = {"id:ID": uid, ":LABEL": label}
                for k in keys:
                    if k in props:
                        row[k] = props[k]
                rows.append(row)
            df = pd.DataFrame(rows, columns=cols)
            path = os.path.join(output_dir, f"nodes_{label}.csv")
            df.to_csv(path, index=False, encoding="utf-8-sig")

        # å…³ç³»
        if self.rels:
            df_rels = pd.DataFrame(self.rels, columns=[":START_ID", ":END_ID", ":TYPE"])
            df_rels.to_csv(os.path.join(output_dir, "relationships.csv"), index=False, encoding="utf-8-sig")


# ========= ä¸»å¤„ç†æµç¨‹ =========

def build_graph() -> None:
    print("ğŸ“¥ åŠ è½½ CIDOC å®šä¹‰è¡¨...")
    rules = load_mapping_rules()
    g = GraphBuilder()

    # ------- é—å€ (E27_Site) -------
    print("ğŸ“¦ å¤„ç†é—å€æ•°æ® (E27_Site)...")
    sites_path = DATA_FILES.get("é—å€")
    if sites_path and os.path.exists(sites_path):
        df_sites = pd.read_csv(sites_path)
        for _, row in df_sites.iterrows():
            site_uid = f"Site_{int(row['ID'])}"
            g.add_node("E27_Site", site_uid, {
                "name": row.get("é—å€åç§°"),
                "type": row.get("é—å€ç±»å‹"),
                "location": row.get("åœ°ç†ä½ç½®"),
            })

    # ------- é—å€ç»“æ„ (E25_ManMade_Feature) -------
    if os.path.exists(STRUCTURES_FILE):
        print("ğŸ“¦ å¤„ç†é—å€ç»“æ„ (E25_ManMade_Feature)...")
        df_struct = pd.read_csv(STRUCTURES_FILE)
        for _, row in df_struct.iterrows():
            sid = int(row["id"])
            struct_uid = f"Structure_{sid}"
            g.add_node("E25_ManMade_Feature", struct_uid, {
                "name": row.get("structure_name"),
                "type": row.get("structure_type"),
                "description": row.get("description"),
            })
            # ç»“æ„ -> é—å€ : P53_has_former_or_current_location
            if "site_id" in row and not pd.isna(row["site_id"]):
                site_uid = f"Site_{int(row['site_id'])}"
                g.add_rel(struct_uid, site_uid, "P53_has_former_or_current_location")
            # ç»“æ„å±‚çº§ï¼šå­ç»“æ„ -> çˆ¶ç»“æ„
            if "parent_id" in row and not pd.isna(row["parent_id"]):
                parent_uid = f"Structure_{int(row['parent_id'])}"
                g.add_rel(struct_uid, parent_uid, "P46i_forms_part_of")

    # ------- æ—¶æœŸ (E4_Period) -------
    print("ğŸ“¦ å¤„ç†æ—¶æœŸæ•°æ® (E4_Period)...")
    periods_path = DATA_FILES.get("æ—¶æœŸ")
    if periods_path and os.path.exists(periods_path):
        df_periods = pd.read_csv(periods_path)
        for _, row in df_periods.iterrows():
            pid = int(row["ID"])
            period_uid = f"Period_{pid}"
            g.add_node("E4_Period", period_uid, {
                "name": row.get("æ—¶æœŸåç§°"),
                "absolute_date": row.get("ç»å¯¹å¹´ä»£"),
                "development_stage": row.get("å‘å±•é˜¶æ®µ"),
            })
            # P7_took_place_at -> Site
            if "site_id" in row and not pd.isna(row["site_id"]):
                site_uid = f"Site_{int(row['site_id'])}"
                g.add_rel(period_uid, site_uid, "P7_took_place_at")

        # æŒ‰ site_id + æ—¶åº å»ºç«‹ P120_occurs_before
        if "site_id" in df_periods.columns and "æ—¶æœŸé¡ºåº" in df_periods.columns:
            for site_id, grp in df_periods.groupby("site_id"):
                try:
                    grp_sorted = grp.sort_values("æ—¶æœŸé¡ºåº")
                except KeyError:
                    continue
                ids = [int(x) for x in grp_sorted["ID"].tolist()]
                for a, b in zip(ids, ids[1:]):
                    g.add_rel(f"Period_{a}", f"Period_{b}", "P120_occurs_before")

    # ------- æ–‡ç‰©ï¼ˆé™¶å™¨ / ç‰å™¨ï¼‰ E22_ManMade_Object -------
    def process_artifacts(art_type_key: str, csv_path: str) -> None:
        if not os.path.exists(csv_path):
            return
        print(f"ğŸ“¦ å¤„ç† {art_type_key} æ–‡ç‰© (E22_ManMade_Object)...")
        df = pd.read_csv(csv_path)

        for _, row in df.iterrows():
            rid = row.get("ID")
            if pd.isna(rid):
                continue
            art_uid = f"Artifact_{art_type_key}_{int(rid)}"
            code = row.get("æ–‡ç‰©ç¼–å·") or row.get("artifact_code")
            g.add_node("E22_ManMade_Object", art_uid, {
                "code": code,
                "category": art_type_key,
                "description": row.get("å°ºå¯¸æè¿°") or row.get("description"),
            })

            # å‡ºåœŸç»“æ„ / é—å€ åŸºç¡€æ‹“æ‰‘ï¼ˆé CIDOC å®šä¹‰è¡¨ï¼Œåˆ©äºå¯¼èˆªï¼‰
            if "structure_id" in row and not pd.isna(row["structure_id"]):
                struct_uid = f"Structure_{int(row['structure_id'])}"
                g.add_rel(art_uid, struct_uid, "P53_has_former_or_current_location")
            elif "å‡ºåœŸå¢“è‘¬" in row and isinstance(row["å‡ºåœŸå¢“è‘¬"], str):
                # å¦‚æœç»“æ„è¡¨ä¸­çš„åç§°ä¸â€œå‡ºåœŸå¢“è‘¬â€ä¸€è‡´ï¼Œå¯åœ¨åç»­å•ç‹¬è¡¥å……æ˜ å°„é€»è¾‘
                pass

            # === æ ¹æ® cidoc-kg-def3 è§„åˆ™ç”Ÿæˆè¯­ä¹‰è·¯å¾„ ===
            for col_name, value in row.items():
                if value is None or value == "" or value != value:
                    continue
                key = (art_type_key, str(col_name).strip())
                rule = rules.get(key)
                if not rule:
                    continue

                range_label = rule["range_class"]

                # ç›®æ ‡èŠ‚ç‚¹ ID ç­–ç•¥
                if "E55" in range_label:
                    # ç±»å‹æ¦‚å¿µï¼šå…¨çƒå…±äº«
                    target_uid = get_uid(range_label, value)
                    g.add_node(range_label, target_uid, {"name": value})
                elif "E57" in range_label:
                    # æè´¨å¯¹è±¡ï¼šæ¯ä»¶æ–‡ç‰©ä¸€ä¸ª
                    target_uid = f"{range_label}_{art_uid}_{col_name}"
                    g.add_node(range_label, target_uid, {"name": value})
                elif "E54" in range_label:
                    # é‡åº¦ï¼šæ¯ä»¶æ–‡ç‰© + æŒ‡æ ‡ å”¯ä¸€
                    target_uid = f"{range_label}_{art_uid}_{col_name}"
                    g.add_node(range_label, target_uid, {
                        "value": value,
                        "metric": col_name,
                    })
                elif "E12" in range_label:
                    # æŸäº›è§„åˆ™å¯èƒ½ç›´æ¥æŒ‡å‘ E12 äº‹ä»¶
                    target_uid = f"{range_label}_{art_uid}"
                    g.add_node(range_label, target_uid, {"name": "Production"})
                else:
                    target_uid = f"{range_label}_{art_uid}_{col_name}"
                    g.add_node(range_label, target_uid, {"value": value})

                inter_class = rule["inter_class"]
                rel1 = rule["rel1"]
                rel2 = rule["rel2"]

                if inter_class:
                    # ä¸­é—´ç±»èŠ‚ç‚¹
                    if "E12" in inter_class:
                        inter_uid = f"{inter_class}_{art_uid}"
                        g.add_node(inter_class, inter_uid, {"name": "Production"})
                    elif "E57" in inter_class:
                        inter_uid = f"{inter_class}_{art_uid}"
                        g.add_node(inter_class, inter_uid, {"name": "Material"})
                    else:
                        inter_uid = f"{inter_class}_{art_uid}_{col_name}"
                        g.add_node(inter_class, inter_uid, {})

                    # E22 -> ä¸­é—´ç±»
                    g.add_rel(art_uid, inter_uid, rel1)
                    # ä¸­é—´ç±» -> ç›®æ ‡ç±»
                    if rel2:
                        g.add_rel(inter_uid, target_uid, rel2)
                    else:
                        g.add_rel(inter_uid, target_uid, "P2_has_type")
                else:
                    # ç›´æ¥å…³ç³»
                    g.add_rel(art_uid, target_uid, rel1)

    # åˆ†åˆ«å¤„ç†é™¶å™¨ã€ç‰å™¨
    for art_type, path in [("é™¶å™¨", DATA_FILES["é™¶å™¨"]), ("ç‰å™¨", DATA_FILES["ç‰å™¨"])]:
        process_artifacts(art_type, path)

    # TODO: é—å€ / æ—¶æœŸå­—æ®µä¹Ÿå¯ä»¥é€šè¿‡ rules è¿›è¡Œè¿›ä¸€æ­¥ä¸°å¯Œï¼Œè¿™é‡Œå…ˆå®ç°æ–‡ç‰©éƒ¨åˆ†çš„å®Œæ•´è·¯å¾„ã€‚

    # å¯¼å‡º
    print("ğŸ“¤ æ­£åœ¨å¯¼å‡º CSV æ–‡ä»¶...")
    g.export(OUTPUT_DIR)
    print(f"âœ… å®Œæˆï¼Œç»“æœå·²å†™å…¥: {OUTPUT_DIR}")


if __name__ == "__main__":
    build_graph()


